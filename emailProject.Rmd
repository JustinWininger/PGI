---
title: "Email Report"
author: "Justin Wininger"
date: "`r Sys.Date()`"
output: word_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE, warning = FALSE, message = F}
knitr::opts_chunk$set(echo = FALSE, dpi = 300)
remove(list = ls())
library(readxl)
library(tidyverse)
library(lubridate)
library(hrbrthemes)
library(viridis)
library(mosaic)

emails <- read_excel("PGI master.xlsx")


emails <- emails %>%
  mutate(`Open Rate` = `Open Rate` * 100)

emails <- emails %>%
  mutate(`Click Rate` = `Click Rate` * 100)

emails <- emails %>%
  mutate(`Bounce Rate` = `Bounce Rate` * 100)
```

```{r message = F, warning = F}
emails$Day <- as.Date(emails$`Sent Date`)
emails$Day <- weekdays(emails$Day)
day_order <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
emails$Day <- factor(emails$Day, levels = day_order, ordered = TRUE)


emails <- emails %>% filter(Topic != 'Test' & `Opens` > 10)

emails$Covid <- ifelse(emails$`Sent Date` < as.Date("2020-03-01"), "Pre-COVID", "Post-COVID")

covid_order <- c("Pre-COVID", "Post-COVID")
emails$Covid <- factor(emails$Covid, levels = covid_order, ordered = TRUE)

counts <- emails %>% 
  group_by(Day) %>%
  tally()

average_recipients <- emails %>%
  group_by(Client) %>%
  summarise(recipientList = median(`Total Recipients`))

average_recipients$Size <- ifelse(average_recipients$recipientList >= 2500, "Large", "Small")

average_recipients <- subset( average_recipients, select = -recipientList )

emails <- left_join(emails, average_recipients, by = 'Client')

large <- emails %>% filter(Size == 'Large')
small <- emails %>% filter(Size == 'Small')

countsL <- large %>% 
    group_by(Client) %>%
    summarize(Count = n())

countsS <- small %>% 
    group_by(Client) %>%
    summarize(Count = n())

countsSL <- full_join(countsS, countsL, by = 'Client')

emailsMF <- emails %>% filter(Day != 'Sunday')

countsMF <- emailsMF %>% 
  group_by(Day) %>%
  tally()

average_recipients <- emails %>%
  group_by(Client) %>%
  summarise(recipientList = median(`Total Recipients`))

average_recipients$Size <- ifelse(average_recipients$recipientList >= 2500, "Large", "Small")

size <- emails %>%
  group_by(Size)%>%
  summarise(
    openRate=median(`Open Rate`),
    clickRate=median(`Click Rate`),
    bounceRate=median(`Bounce Rate`)
    )

size <- subset( size, select = -Size )

chisqS <- chisq.test(size)
#p = 0.9185

emailsBC <- subset(emailsMF, Covid == "Pre-covid")
emailsAC <- subset(emailsMF, Covid == "Post-covid")

countsMF2 <- emailsMF %>% 
  group_by(Day, Covid) %>%
  tally()

emails <- emails %>% mutate(`Subject Length` = nchar(Subject))

SL <- lm(`Open Rate` ~ `Subject Length`, data = emails)

sSL <- summary(SL)

sSLo <- sSL[["coefficients"]]

has_punctuation <- function(text) {
  grepl("[[:punct:]]", text)
}

# Add a new column 'contains_punctuation' based on the presence of punctuation
emails <- emails %>%
  mutate(Punctuation = ifelse(has_punctuation(Subject), "Yes", "No"))

punctuation <- emails %>%
  group_by(Punctuation)%>%
  summarise(
    openRate=round(median(`Open Rate`), digits =2),
    clickRate=round(median(`Click Rate`), digits =2),
    bounceRate=round(median(`Bounce Rate`), digits =2)
    )

punctuation <- subset( punctuation, select = -Punctuation )

chisqP <- chisq.test(punctuation)
#p = 0.8956

counts2 <- emails %>% 
  group_by(Punctuation) %>%
  tally()

# Function to check for specific punctuation marks
has_period <- function(text) {
  grepl("\\.", text)
}

has_colon <- function(text) {
  grepl(":", text)
}

has_exclamation <- function(text) {
  grepl("!", text)
}

has_question <- function(text) {
  grepl("\\?", text)
}

has_comma <- function(text) {
  grepl("\\,", text)
}

has_hyphen <- function(text) {
  grepl("\\-", text)
}

has_ampersand <- function(text) {
  grepl("\\&", text)
}

has_quote <- function(text) {
  grepl('\\"', text)
}

has_em <- function(text) {
  grepl('\\—', text)
}

has_em2 <- function(text) {
  grepl('\\–', text)
}

has_slash <- function(text) {
  grepl('\\/', text)
}

# Add new columns for specific punctuation marks
emails <- emails %>%
  mutate(
    Period = ifelse(has_period(Subject), "Yes", "No"),
    Colon = ifelse(has_colon(Subject), "Yes", "No"),
    ExclamationPoint = ifelse(has_exclamation(Subject), "Yes", "No"),
    QuestionMark = ifelse(has_question(Subject), "Yes", "No"),
    Comma = ifelse(has_comma(Subject), "Yes", "No"),
    Hyphen = ifelse(has_hyphen(Subject), "Yes", "No"),
    Ampersand = ifelse(has_ampersand(Subject), "Yes", "No"),
    Quote = ifelse(has_quote(Subject), "Yes", "No"),
    Em = ifelse(has_em(Subject), "Yes", "No"),
    Em2 = ifelse(has_em2(Subject), "Yes", "No"),
    Slash = ifelse(has_slash(Subject), "Yes", "No")
  )

haveP <- emails %>%
  filter(Period == "Yes") %>%
  mutate(Punc = "Period")
haveC <- emails %>%
  filter(Colon == "Yes") %>%
  mutate(Punc = "Colon")
haveE <- emails %>%
  filter(ExclamationPoint == "Yes")%>%
  mutate(Punc = "Exclamation\nPoint")
haveQ <- emails %>%
  filter(QuestionMark == "Yes")%>%
  mutate(Punc = "Question\nMark")
haveN <- emails %>%
  filter(Punctuation == "No")%>%
  mutate(Punc = "None")
haveCom <- emails %>%
  filter(Comma == 'Yes')%>%
  mutate(Punc = 'Comma')
haveD <- emails %>%
  filter(Hyphen == 'Yes' | Em == 'Yes' | Em2 == 'Yes')%>%
  mutate(Punc = 'Dash')
haveAmp <- emails %>%
  filter(Ampersand == 'Yes')%>%
  mutate(Punc = 'Ampersand')
haveQuo <- emails %>%
  filter(Quote == 'Yes')%>%
  mutate(Punc = 'Quotes')
haveSlash <- emails %>%
  filter(Slash == 'Yes')%>%
  mutate(Punc = 'Slash')


tmp <- emails %>% filter(Punctuation == 'Yes' & (Hyphen == 'Yes' | Em == 'Yes' | Em2 == 'Yes'))

havePunc <- do.call("rbind", list(haveP, haveC, haveE, haveQ, haveN, haveCom, haveD, haveAmp, haveQuo, haveSlash))

havePunc <- havePunc %>% 
  group_by(Punc) %>%
  filter(n() >= 15)

counts7 <- havePunc %>% 
  group_by(Punc) %>%
  tally()

analyze_last_char <- function(text) {
  last_char <- substr(text, nchar(text), nchar(text))
  if (last_char == ".") {
    return("Period")
  } else if (last_char == "!") {
    return("Exclamation")
  } else if (last_char == "?") {
    return("Question")
  } else if (last_char == ":") {
    return("Colon")
  } else if (last_char == "&") {
    return("Ampersand")
  } else if (last_char == ",") {
    return("Comma")
  } else if (last_char == "/") {
    return("Slash")
  } else if (last_char == '"') {
    return("Quotes")
  } else if (last_char == "-" | last_char == "—" | last_char == "–") {
    return("Dash")
  } else {
    return("No Punctuation")
  }
}

# Create new column with analysis of last character
emails$lastChar <- sapply(emails$Subject, analyze_last_char)

emailsLC <- emails %>% 
  filter(lastChar == 'Period' | lastChar == 'No Punctuation') 

counts6 <- emails %>% 
  group_by(lastChar) %>%
  tally()

counts3 <- emailsLC %>% 
  group_by(lastChar) %>%
  tally()

noPunc <- emails %>% filter(Punctuation == "No")
noPunc <- noPunc %>%
  mutate (Source = "No Punctuation")
emailsNP <- emailsLC %>% 
  filter(lastChar == 'No Punctuation') %>%
  mutate (Source = "No Ending Punctuation")
emailsP <- emailsLC %>% 
  filter(lastChar == 'Period')%>%
  mutate (Source = "Ending Period") 
tmp <- rbind(emailsNP, emailsP)
both <- rbind(tmp, noPunc)

countsBoth <- both %>% 
  group_by(Source) %>%
  tally()

both2 <- rbind(emailsP, noPunc)

countsBoth2 <- both2 %>% 
  group_by(Source) %>%
  tally()

countsSize <- emails %>% 
  group_by(Size) %>%
  tally()

emails <- emails %>%
  group_by(Client, Subject) %>%
  mutate(Duplicate = if_else(n_distinct(`Sent Date`) > 1, "Yes", "No")) %>%
  ungroup()

countsDup <- emails %>% 
  group_by(Duplicate) %>%
  tally()

analyze_keywords <- function(data, subject_col, keywords) {
  emails <- emails %>%
    mutate(across(all_of(subject_col), tolower, .names = "lower_{col}"))
  
  for (keyword_group in keywords) {
    # Split the keywords if there are synonyms
    keyword_synonyms <- unlist(strsplit(keyword_group, "/"))
    base_keyword <- keyword_synonyms[1]
    
    # Create a new column name
    new_col_name <- paste0("have", base_keyword)
    
    # Check if any of the synonyms are in the subject column
    emails[[new_col_name]] <- ifelse(grepl(paste(keyword_synonyms, collapse = "|"), emails[[paste0("lower_", subject_col)]]), "Yes", "No")
  }
  
  # Check for numbers 1-10 in both numeric and written form
  numbers_written <- c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten")
  numbers_numeric <- as.character(1:10)
  all_numbers <- c(numbers_written, numbers_numeric)
  emails[["haveNumber"]] <- ifelse(grepl(paste(all_numbers, collapse = "|"), emails[[paste0("lower_", subject_col)]]), "Yes", "No")
  
  # Remove the temporary lowercase subject column
  emails <- emails %>%
    select(-starts_with("lower_"))
  
  return(emails)
}

# Example usage
# Assuming `df` is your dataset and `Subject` is the column to analyze
keywords <- c("gift/gifts", "legacy/legacies", "easy/smart/simple", "you/your/yours", 
              "impact/effect/affect", "option/options", "meaningful", "wise", 
              "support", "year-end", "give", "reward/rewarding", "will", 
              "support", "tax/taxes", "us/we", "help", "plan/planning")

# Applying the function to the dataset
emails <- analyze_keywords(emails, "Subject", keywords)

haveGift <- emails %>%
  filter(havegift == "Yes") %>%
  mutate(Keyword = "Gift(s)")
haveLegacy <- emails %>%
  filter(havelegacy == "Yes") %>%
  mutate(Keyword = "Legacy(ies)")
haveEasy <- emails %>%
  filter(haveeasy == "Yes")%>%
  mutate(Keyword = "Easy / Smart / Simple")
haveYou <- emails %>%
  filter(haveyou == "Yes")%>%
  mutate(Keyword = "You / Your / Yours")
haveImpact <- emails %>%
  filter(haveimpact == "Yes")%>%
  mutate(Keyword = "Impact / Effect")
haveOption <- emails %>%
  filter(haveoption == 'Yes')%>%
  mutate(Keyword = 'Option(s)')
haveMeaningful <- emails %>%
  filter(havemeaningful == 'Yes')%>%
  mutate(Keyword = 'Meaningful')
haveWise <- emails %>%
  filter(havewise == 'Yes')%>%
  mutate(Keyword = 'Wise')
haveSupport <- emails %>%
  filter(havesupport == 'Yes')%>%
  mutate(Keyword = 'Support')
haveYearEnd <- emails %>%
  filter(`haveyear-end` == 'Yes')%>%
  mutate(Keyword = 'Year-End')
haveNumber <- emails %>%
  filter(haveNumber == "Yes") %>%
  mutate(Keyword = "A Number")
haveGive <- emails %>%
  filter(havegive == "Yes") %>%
  mutate(Keyword = "Give")
haveReward <- emails %>%
  filter(havereward == "Yes")%>%
  mutate(Keyword = "Reward(ing)")
haveWill <- emails %>%
  filter(havewill == "Yes")%>%
  mutate(Keyword = "Will")
haveTax <- emails %>%
  filter(havetax == "Yes")%>%
  mutate(Keyword = "Tax(es)")
haveUs <- emails %>%
  filter(haveus == 'Yes')%>%
  mutate(Keyword = 'Us / We')
haveHelp <- emails %>%
  filter(havehelp == 'Yes')%>%
  mutate(Keyword = 'Help')
havePlan <- emails %>%
  filter(haveplan == 'Yes')%>%
  mutate(Keyword = 'Plan(ning)')

keywords <- do.call("rbind", list(haveGift, haveLegacy, haveEasy, haveYou, haveImpact, haveOption, haveMeaningful, haveWise, haveSupport, haveYearEnd, haveNumber, haveGive, haveReward, haveWill, haveTax, haveUs, haveHelp, havePlan))

countsKeywords <- keywords %>% 
  group_by(Keyword) %>%
  tally()

techniques <- emails %>% filter(`Product Type` == 'Techniques')

topics <- emails %>% 
  group_by(Topic) %>%
  filter(n() >= 15)

countsTopics <- topics %>% 
  group_by(Topic) %>%
  tally()

countsTechniques <- techniques %>% 
  group_by(Day) %>%
  tally()

countsTechniques2 <- techniques %>% 
  group_by(Day, Covid) %>%
  tally()
```

# Introduction

This report analyzes several statistics of 645 email campaigns including over 1.5 million emails sent out by 59 nonprofit organizations represented by Endowment Development Services since 2010. When comparing two or more groups, this report will use the median instead of the mean or average. The median, being the point where there are equal amounts of observations larger and smaller, is more resistant to outliers than the mean and is therefore a much better representation of the "typical" observation. This report will mainly observe the open rate and click rate of these various email campaigns. Because it is physically impossible for either one to be negative, both will be skewed to the right. Because of this, using the mean would result in inflated and unrealistic claims. Using the median, therefore, is the best choice.

# Size

Nonprofit organizations sizes within these data vary wildly. Some have list sizes of just 50, while others have list sizes of almost 30,000. The average list size is only 2,473. Using 2,500 as an arbitrary benchmark between small and large, among the 59 nonprofit organizations represented, 27 of them are considered large and 32 of them are small. More statistics are in the table below.

| Size  | Count | Median List Size | Median Open Rate | Median Click Rate | Median Bounce Rate |
|:----------:|:----------:|:----------:|:----------:|:----------:|:----------:|
|  All  |  59   |       1403       |      33.27%      |       0.97%       |       4.73%        |
| Large |  27   |       4219       |      33.28%      |       0.87%       |       3.88%        |
| Small |  32   |       838        |      32.99%      |       1.18%       |       4.98%        |

Looking at the table, the results do not appear to be significantly different. Performing a Chi-Square Test for Homogeneity confirms it. There is not a statistically significant difference between large and small list sizes in open rate, click rate, or bounce rate.

# Day of the Week

Once work on an email campaign is finished, perhaps the biggest question faced is when to send it. Below is a side-by-side box and whisker plot of the open rate plotted by day of the week. The lime colored line represents the median open rate for each day. The white text is that median.

```{r message=FALSE, warning=FALSE}
#| fig.cap="Open Rate by Day of the Week",
latex_options = c("HOLD_position")
ggplot(data=emailsMF, mapping=aes(x=Day, y=`Open Rate`, fill = Day))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  labs(title = 'Open Rate by Day of the Week')+
  geom_text(data = countsMF,
            aes(Day, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")
```

This visualization reveals that not all days are created equal. Unfortunately, there was not enough data on Saturday or Sunday, so they were excluded. Friday and Tuesday seem to be the best days to send campaigns, and Wednesday and Thursday are the worst days. This relationship is statistically significant. Despite being statistically significant, there is always still the chance that any variation seen is due to random chance or lurking variables. For example, perhaps the nonprofits with the most loyal donors happen to have a policy to send campaigns on Fridays. This would skew the data. Sending campaigns on Tuesdays or Fridays, therefore, is not a guarantee the open rate will increase, but those days are the best bet to get a higher open rate.

Interestingly, the days with the highest median click rate are Thursday and Wednesday, respectively. The two lowest days are Monday and Friday. Friday being the worst day for clicks is very surprising, especially considering that it is the best day for opens. This disparity makes a "best day" very hard to determine. Some days have high open rates, while other days have high click rates. Ultimately, it will be up to the individual to decide which is more valuable to him: opens or clicks. The only thing that can definitively be said is that Mondays have low open and click rates; do not send email campaigns on Mondays.

## COVID-19

Unfortunately, the practice of donating to nonprofits was not unaffected by the pandemic. It might have ended up, however, being a net positive. Open and click rates for every single day increased after COVID, as seen in the visualization below.

```{r}
emailsMF %>%
  ggplot(aes(Day, `Open Rate`, fill = Day,))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
      axis.text.x = element_text(angle = 90, hjust=1)
    )+
  labs(title = 'Open Rate by Day of the Week Relative to COVID-19')+
  facet_wrap( ~ Covid)+
  geom_text(data = countsMF2,
            aes(Day, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 1), "%")),
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")
```

The observed shift makes sense. The pandemic forced people to digitize. A direct result of this digitization is that people spent more time working on their computers, which gives them more opportunities to check their emails. Median open rates increased, but so did the variability. This is represented by the size of the box. The bottom of the box is called the first quartile. It is the 25th percentile. The top of the box is called the third quartile and is the 75th percentile. Half of all observations, therefore, are contained within the box. Because the post-COVID boxes are taller, the data is more variable and has a wider range. Looking at only post-COVID, the best days to send campaigns for open rates are still Tuesday and Friday. However, Monday is now much better than it was, and Wednesday is much worse than it was.

COVID made click rate decrease. The median click rate before the pandemic was 1.39%, but it is 0.86% after the pandemic. The days with the best click rates post-pandemic are Wednesday and Thursday, and the worst days are Monday and Friday. Once again, because the best days for open and click rate differ, it is up to the individual which is more important.

# Subject Line

The subject line is one of if not the most important parts of an email when it comes to engaging a potential donor. It is the first thing he will see. It is imperative, therefore, to maximize the effectiveness of the subject line.

## Subject Length

Are longer subjects more engaging? Below is a scatterplot that shows open rate by subject length in characters.

```{r warning = F, message = F}
ggplot(data=emails, mapping=aes(x=`Subject Length`, y=`Open Rate`))+
  geom_point(color = c('#0091b3'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  geom_smooth(method=lm,se=FALSE, color = '#003a5d', formula = y~x)+
  labs(title = 'Open Rate by Subject Length',
       x = 'Subject Length (characters)')
```

The pattern of the points shows no clear relationship, but the line of best fit has a definite negative slope. This should mean that as subject length increases, open rate decreases. This relationship is even statistically significant. $R^2$ is a measure of goodness-of-fit. It essentially measures how much the variation in open rate is caused by subject length. The $R^2$ value for this model is 1.01%. Only 1% of the variation in open rate is caused by subject length. So, even though the negative linear relationship is statistically significant, the impact of subject length on open rate is essentially 0. It is safe to conclude, therefore, that subject length does not realistically matter when observing open rate, as long as subject length is somewhere between 15 and 90 characters.

## Punctuation

Below is a table comparing subjects with punctuation versus subjects without punctuation.

| Punctuation | Count | Median Open Rate | Median Click Rate |
|:-----------:|:-----:|:----------------:|:-----------------:|
|     No      |  178  |      34.69%      |       0.73%       |
|     Yes     |  432  |      32.84%      |       1.26%       |

Like before, the presence of punctuation does not significantly affect open or click rate. However, just like the days of the week, one must choose whether he wants a higher open or click rate. Subject lines with no punctuation have a higher open rate, but subject lines with punctuation have a higher click rate.

### Types of Punctuation

Punctuation alone is not enough information. There are tens of different types of punctuation. Below is a plot showing all types of punctuation with at least 15 observations.

```{r}
havePunc %>%
  ggplot(aes(x = reorder(Punc, `Open Rate`, FUN = median), y = `Open Rate`, fill = Punc))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  theme_ipsum(axis_title_size = 12) +
  theme(
    legend.position="none",
    )+
  labs(title = "Open Rate by Type of Punctuation",
       x = 'Punctuation')+
  geom_text(data = counts7,
            aes(Punc, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

```

This visualization is unusual in that is contains some observations multiple times. For example, a subject line with a colon, dash, and period would be included three times, once in each box. Based on the plot, dashes do not perform well and periods perform the best. As expected, click rates are the exact opposite. Dashes have the highest median click rate, and periods have the lowest. Subject lines, however, are designed to persuade people to open the email, not necessarily to click within it. When discussing subject lines, therefore, catering to open rates is much more important.

### Last Character

Within a subject line, the last character may be among the most important. Below is a violin plot comparing the difference between ending a subject with a period versus ending it with no punctuation at all. This violin plot contains the all-too-familiar boxplot, but also includes the distribution of the groups.

```{r message = F, warning = F}
emailsLC %>%
  ggplot( aes(x=lastChar, y=`Open Rate`, fill=lastChar)) +
    geom_violin(width=1.0) +
    geom_boxplot(width=0.3, color="black", alpha=0.2) +
    scale_fill_viridis(discrete = TRUE) +
    theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  geom_text(data = counts3,
            aes(lastChar, Inf, label = n), vjust = 1) +
  labs(x= 'Last Character',
       y= 'Open Rate',
       title = ' Open Rate by Last Character')+
  scale_fill_manual(values=c('#003a5d', '#0091b3'))+
  stat_summary(fun = median, geom = "crossbar", width = .3, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

modelLC <- lm(`Open Rate` ~ lastChar, emailsLC)
anovaLC <- anova(modelLC)
#p = 2.27148e-06
```

The boxplots alone reveal that ending with a period seems to be significantly better. The violin plot tells the same story, but to an even greater extent. The violin shows the distribution of observations. Where the violin is wider, there are more observations. It is very evident from this plot that ending the subject line with a period is significantly better. Plots alone are not enough, though. Luckily, Analysis of Variance (ANOVA) agrees with the plots and returns a statistically significant result. Naturally, however, click rates show the opposite relationship. Like previously stated though, click rates do not really matter in this context.

### Duplicate Subjects

Email campaigns sent by the same nonprofit can go one of two routes: unique subjects or identical subjects. Some nonprofits will send a new, fresh subject line for every campaign. Others will send the same or very similar subject lines for every campaign. Below is a table analyzing key statistics for duplicate subject lines.

| Duplicate | Median Open Rate | Median Click Rate | Median Bounce Rate |
|:---------:|:----------------:|:-----------------:|:------------------:|
|    No     |      33.07%      |       0.91%       |       4.17%        |
|    Yes    |      34.06%      |       1.40%       |       6.00%        |

```{r}
dupes <- emails %>% 
  group_by(Duplicate) %>% 
  summarise(
    openRate=round(median(`Open Rate`), digits =4),
    clickRate=round(median(`Click Rate`), digits =4),
    bounceRate=round(median(`Bounce Rate`), digits =4),
    spamRate=round(median(`Spam Rate`), digits =4)
    )
```

```{r plots, warning = FALSE, message = F}
both2 %>%
  ggplot(aes(Source, `Open Rate`, fill = Source))+
  geom_boxplot(fill = c('#003a5d', '#0091b3'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  labs(title = "Open Rate by Punctuation",
       x = "Punctuation")+
  geom_text(data = countsBoth2,
            aes(Source, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

modelBoth2 <- lm(`Open Rate` ~ Source, both2)
anovaB2 <- anova(modelBoth2)
#p = 0.005394861

emails %>% 
  ggplot(aes(Size, `Open Rate`, fill = Size))+
  geom_boxplot(fill = c('#003a5d', '#0091b3'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  labs(title = "Open Rate by Company Size")+
  geom_text(data = countsSize,
            aes(Size, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

sizeM <- lm(`Open Rate` ~ Size, emails)
asizeM <- anova(sizeM)
#p = 0.1473003

emails %>%
  ggplot(aes(Duplicate, `Open Rate`))+
  geom_boxplot(fill = c('#003a5d', '#0091b3'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
    )+
  labs(title = "Open Rate by Duplicate Subjects")+
  geom_text(data = countsDup,
            aes(Duplicate, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

modelD <- lm(`Open Rate` ~ Duplicate, data = emails)
anovaD <- anova(modelD)
#p = 0.7162413

keywords %>%
  ggplot(aes(x = reorder(Keyword, `Open Rate`, FUN = median), y = `Open Rate`))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3'))+
  geom_text(data = countsKeywords,
            aes(Keyword, Inf, label = n), vjust = 1)+
  theme_ipsum(axis_title_size = 12)+
  theme(axis.text.x = element_text(angle = 90, hjust=1))+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  labs(title = "Open Rate by Presence of Keywords",
       x = 'Keyword')

modelK <- lm(`Open Rate` ~ Keyword, keywords)
anovaK <- anova(modelK)
#p = 0.0001408233

techniques %>%
  ggplot(aes(Day, `Open Rate`, fill = Day))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  geom_text(data = countsTechniques,
            aes(Day, Inf, label = n), vjust = 1)+
  theme_ipsum()+
  labs(title = 'Open Rate by Day of the Week for Technique Emails')+
  theme(legend.position="none")+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 2), "%")), 
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

techniques %>%
  ggplot(aes(Day, `Open Rate`, fill = Day,))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  theme_ipsum(axis_title_size = 12) +
    theme(
      legend.position="none",
      axis.text.x = element_text(angle = 90, hjust=1)
    )+
  labs(title = 'Open Rate by Day of the Week Relative to COVID-19 for Technique Emails')+
  facet_wrap( ~ Covid)+
  geom_text(data = countsTechniques2,
            aes(Day, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 1), "%")),
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")
  
     
topics %>%
  ggplot(aes(x = reorder(Topic, `Open Rate`, FUN = median), y = `Open Rate`, fill = Topic))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d', '#0091b3', '#003a5d'))+
  theme_ipsum()+
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        legend.position = 'none')+
  labs(title = 'Open Rate by Topic',
       x = 'Topic')+
  geom_text(data = countsTopics,
            aes(Topic, Inf, label = n), vjust = 1)+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 1), "%")),
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")

emails %>%
  ggplot(aes(x = reorder(`Product Type`, `Open Rate`, FUN = median), y = `Open Rate`, fill = `Product Type`))+
  geom_boxplot(fill = c('#003a5d', '#0091b3', '#003a5d', '#0091b3',  '#003a5d'))+
  theme_ipsum()+
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        legend.position = 'none')+
  labs(title = 'Click Rate by Product Type',
       x = 'Topic')+
  stat_summary(fun = median, geom = "crossbar", width = .75, color = "#a9ad00", size = .4)+
  stat_summary(fun = median, geom = "text", aes(label = paste0(round(..y.., 1), "%")),
               position = position_dodge(width = 0.75), vjust = -0.5, color = "white")
```
